{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding, LSTM\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfSeventh = pd.read_csv('./textsSeventhgrade.csv')\n",
    "dfEighth = pd.read_csv('./textsEighthgrade.csv')\n",
    "dfNinth = pd.read_csv('./textsNinthgrade.csv')\n",
    "dfTenth = pd.read_csv('./textsTenthGrade.csv')\n",
    "dfEleventh = pd.read_csv('./textsEleventhgrade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedSeventh = dfSeventh.groupby('id').apply(lambda x: \"%s\" % ''.join(x['value']))\n",
    "groupedEighth = dfEighth.groupby('id').apply(lambda x: \"%s\" % ''.join(x['value']))\n",
    "groupedNinth = dfNinth.groupby('id').apply(lambda x: \"%s\" % ''.join(x['value']))\n",
    "groupedTenth = dfTenth.groupby('id').apply(lambda x: \"%s\" % ''.join(x['value']))\n",
    "groupedEleventh = dfEleventh.groupby('id').apply(lambda x: \"%s\" % ''.join(x['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(groupedSeventh.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.concatenate((np.array(groupedSeventh.values),\n",
    "                       np.array(groupedEighth.values),\n",
    "                       np.array(groupedNinth.values),\n",
    "                       np.array(groupedTenth.values),\n",
    "                       np.array(groupedEleventh.values)  )) \n",
    "labels = np.concatenate((np.full(len(groupedSeventh.values), 0),\n",
    "                         np.full(len(groupedEighth.values), 1),\n",
    "                         np.full(len(groupedNinth.values), 2),\n",
    "                         np.full(len(groupedTenth.values), 3),\n",
    "                         np.full(len(groupedEleventh.values), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_DIMESION = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000654 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddingsIndex = dict()\n",
    "f = open('./pretrained-word-vectors-for-spanish/SBW-vectors-300-min5.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddingsIndex[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddingsIndex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createEmbedingMatrix(tokenizer, vocabSize):\n",
    "    embeddingMatrix = np.zeros((vocabSize, 300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embeddingVector = embeddingsIndex.get(word)\n",
    "        if embeddingVector is not None:\n",
    "            embeddingMatrix[i] = embeddingVector\n",
    "    return embeddingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    vocabSize = len(tokenizer.word_index) + 1\n",
    "    encodedData = tokenizer.texts_to_sequences(x)\n",
    "    maxLength = 500\n",
    "    paddedData = pad_sequences(encodedData, maxlen=maxLength, padding='post')\n",
    "    embeddings = createEmbedingMatrix(tokenizer, vocabSize)\n",
    "    \n",
    "    return paddedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTrainData(x):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    vocabSize = len(tokenizer.word_index) + 1\n",
    "    encodedData = tokenizer.texts_to_sequences(x)\n",
    "    maxLength = 500\n",
    "    paddedData = pad_sequences(encodedData, maxlen=maxLength, padding='post')\n",
    "    embeddings = createEmbedingMatrix(tokenizer, vocabSize)\n",
    "    \n",
    "    return paddedData, embeddings, maxLength, vocabSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokenize, x_train_embeddings, x_train_max_features, x_train_vocab_size  = createTrainData(x_train)\n",
    "x_test_tokenize = tokenize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13424, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testModels(paramsArr):\n",
    "    resultMetrics = list();\n",
    "    resultPredict = list();\n",
    "    \n",
    "    for params in paramsArr:\n",
    "        batch_size = params[0]\n",
    "        numOfCells = params[1]\n",
    "        epochs = params[2]\n",
    "        # Model definition\n",
    "        model = Sequential()\n",
    "        adam = Adam(lr=0.001)\n",
    "        embeddingLayer = Embedding(x_train_vocab_size,\n",
    "                                   EMBEDDINGS_DIMESION,\n",
    "                                   weights=[x_train_embeddings],\n",
    "                                   input_length=x_train_max_features,\n",
    "                                   trainable=False)\n",
    "        model.add(embeddingLayer)\n",
    "        model.add(LSTM(numOfCells))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=adam)\n",
    "        # Model Train\n",
    "        model.fit(x_train_tokenize, y_train, epochs=epochs, batch_size=batch_size)\n",
    "        # Model Prediction\n",
    "        y_predict = model.predict(x_test_tokenize)\n",
    "        y = np.argmax(y_predict, axis=1)\n",
    "        # Metrics calculation\n",
    "        f1_result_score = f1_score(y_test, y, average='macro')\n",
    "        precision_result_score = precision_score(y_test, y, average='macro')\n",
    "        recall_result_score = recall_score(y_test, y, average='macro')\n",
    "        accuracy_result_score = accuracy_score(y_test, y)\n",
    "        resultPredict.append(y)\n",
    "        resultMetrics.append([f1_result_score, precision_result_score, recall_result_score, accuracy_result_score])\n",
    "\n",
    "    return resultMetrics, resultPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testParams = [\n",
    "  [22, 100, 10],\n",
    "  [32, 4, 10],\n",
    "  [64, 16, 20],\n",
    "  [32, 16, 20],\n",
    "  [64, 32, 30],\n",
    "  [64, 100, 30],\n",
    "  [32, 32, 30],\n",
    "  [64, 64, 40],\n",
    "  [64, 64, 40],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testParams2 = [\n",
    "  [32, 16, 20],\n",
    "  [32, 32, 20],\n",
    "  [32, 64, 20],\n",
    "  [32, 128, 20],\n",
    "  [32, 256, 20],\n",
    "  [64, 64, 40],\n",
    "  [64, 128, 40],\n",
    "  [64, 256, 40],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics, predictions = testModels(testParams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSES = [\"Seventh Grade\", \"Eighth Grade\", \"Ninth grade\", \"Tenth grade\", \"Eleven grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusionMatrixs = list()\n",
    "\n",
    "for prediction in predictions:\n",
    "    confusionMatrix = confusion_matrix(y_test, prediction)\n",
    "    np.set_printoptions(precision=2)\n",
    "    confusionMatrixs.append(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(confusionMatrixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSES = [\"Seventh Grade\", \"Eighth Grade\", \"Ninth grade\", \"Tenth grade\", \"Eleven grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusionMatrixs = list()\n",
    "\n",
    "for prediction in predictions:\n",
    "    confusionMatrix = confusion_matrix(y_test, prediction)\n",
    "    np.set_printoptions(precision=2)\n",
    "    confusionMatrixs.append(confusionMatrix)\n",
    "\n",
    "len(confusionMatrixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
